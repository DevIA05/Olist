{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "# Remplacez ces valeurs par les informations de votre base de données\n",
    "db_host = \"localhost\"\n",
    "db_name = \"olist\"\n",
    "db_user = \"postgres\"\n",
    "db_password = \"admin\"\n",
    "\n",
    "# Créer une connexion avec la base de données en utilisant sqlalchemy\n",
    "engine = create_engine(f\"postgresql://{db_user}:{db_password}@{db_host}/{db_name}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>customer_unique_id</th>\n",
       "      <th>customer_zip_code_prefix</th>\n",
       "      <th>customer_city</th>\n",
       "      <th>customer_state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>06b8999e2fba1a1fbc88172c00ba8bc7</td>\n",
       "      <td>861eff4711a542e4b93843c6dd7febb0</td>\n",
       "      <td>14409</td>\n",
       "      <td>franca</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18955e83d337fd6b2def6b18a428ac77</td>\n",
       "      <td>290c77bc529b7ac935b93aa66c333dc3</td>\n",
       "      <td>9790</td>\n",
       "      <td>sao bernardo do campo</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4e7b3e00288586ebd08712fdd0374a03</td>\n",
       "      <td>060e732b5b29e8181a18229c7b0b2b5e</td>\n",
       "      <td>1151</td>\n",
       "      <td>sao paulo</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b2b6027bc5c5109e529d4dc6358b12c3</td>\n",
       "      <td>259dac757896d24d7702b9acbbff3f3c</td>\n",
       "      <td>8775</td>\n",
       "      <td>mogi das cruzes</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4f2d8ab171c80ec8364f7c12e35b23ad</td>\n",
       "      <td>345ecd01c38d18a9036ed96c73b8d066</td>\n",
       "      <td>13056</td>\n",
       "      <td>campinas</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        customer_id                customer_unique_id   \n",
       "0  06b8999e2fba1a1fbc88172c00ba8bc7  861eff4711a542e4b93843c6dd7febb0  \\\n",
       "1  18955e83d337fd6b2def6b18a428ac77  290c77bc529b7ac935b93aa66c333dc3   \n",
       "2  4e7b3e00288586ebd08712fdd0374a03  060e732b5b29e8181a18229c7b0b2b5e   \n",
       "3  b2b6027bc5c5109e529d4dc6358b12c3  259dac757896d24d7702b9acbbff3f3c   \n",
       "4  4f2d8ab171c80ec8364f7c12e35b23ad  345ecd01c38d18a9036ed96c73b8d066   \n",
       "\n",
       "   customer_zip_code_prefix          customer_city customer_state  \n",
       "0                     14409                 franca             SP  \n",
       "1                      9790  sao bernardo do campo             SP  \n",
       "2                      1151              sao paulo             SP  \n",
       "3                      8775        mogi das cruzes             SP  \n",
       "4                     13056               campinas             SP  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lire le fichier CSV avec pandas\n",
    "data = pd.read_csv(\"data/olist_customers_dataset.csv\", encoding=\"utf-8\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_codes = data[['customer_zip_code_prefix']].drop_duplicates()\n",
    "zip_codes.columns = ['zip_code_prefix']\n",
    "\n",
    "states = data[['customer_state']].drop_duplicates()\n",
    "states.columns = ['state_code']\n",
    "\n",
    "cities = data[['customer_city', 'customer_state']].drop_duplicates()\n",
    "cities.columns = ['city_name', 'state_code']\n",
    "\n",
    "city_zip_codes = data[['customer_city', 'customer_state', 'customer_zip_code_prefix']].drop_duplicates()\n",
    "city_zip_codes.columns = ['city_name', 'state_code', 'zip_code_prefix']\n",
    "\n",
    "customers = data[['customer_id', 'customer_unique_id', 'customer_zip_code_prefix']].drop_duplicates()\n",
    "customers.columns = ['customer_id', 'customer_unique_id', 'zip_code_prefix']\n",
    "\n",
    "zip_codes.to_sql('olist_zipcode', engine, if_exists='append', index=False)\n",
    "states.to_sql('olist_state', engine, if_exists='append', index=False)\n",
    "cities.to_sql('olist_city', engine, if_exists='append', index=False)\n",
    "customers.to_sql('olist_customer', engine, if_exists='append', index=False)\n",
    "\n",
    "# Récupérer les city_id à partir de la base de données\n",
    "cities_db = pd.read_sql(\"SELECT city_id, city_name, state_code FROM olist_city\", engine)\n",
    "\n",
    "# Joindre les DataFrames\n",
    "city_zip_codes_joined = city_zip_codes.merge(cities_db, on=['city_name', 'state_code'])\n",
    "\n",
    "# Insérer les données dans la table city_zip_code\n",
    "city_zip_codes_joined[['city_id', 'zip_code_prefix']].to_sql('olist_cityzipcode', engine, if_exists='append', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lire le fichier CSV avec pandas\n",
    "data = pd.read_csv(\"data/olist_orders_dataset.csv\", encoding=\"utf-8\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_columns = ['order_approved_at', 'order_purchase_timestamp', 'order_delivered_carrier_date', 'order_delivered_customer_date', 'order_estimated_delivery_date']\n",
    "for column in date_columns:\n",
    "    data[column] = pd.to_datetime(data[column])\n",
    "\n",
    "data.to_sql('olist_order', engine, if_exists='append', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Order Payments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lire le fichier CSV avec pandas\n",
    "data = pd.read_csv(\"data/olist_order_payments_dataset.csv\", encoding=\"utf-8\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_sql('olist_orderpayment', engine, if_exists='append', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Order Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lire le fichier CSV avec pandas\n",
    "data = pd.read_csv(\"data/olist_order_reviews_dataset.csv\", encoding=\"utf-8\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_sql('olist_orderreview', engine, if_exists='append', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Product Category Name Traductions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lire le fichier CSV avec pandas\n",
    "data = pd.read_csv(\"data/product_category_name_translation.csv\", encoding=\"utf-8\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_sql('olist_productcategorynametranslation', engine, if_exists='append', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lire le fichier CSV avec pandas\n",
    "data = pd.read_csv(\"data/olist_products_dataset.csv\", encoding=\"utf-8\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.rename(columns={\"product_category_name\": \"product_category_name_translation\"})\n",
    "\n",
    "unique_categories = set(data[\"product_category_name_translation\"].dropna().unique())\n",
    "existing_categories = pd.read_sql(\"SELECT product_category_name FROM olist_productcategorynametranslation\", engine)\n",
    "missing_categories = unique_categories - set(existing_categories[\"product_category_name\"].values)\n",
    "\n",
    "if missing_categories:\n",
    "    missing_categories_df = pd.DataFrame({\"product_category_name\": list(missing_categories),\n",
    "                                          \"product_category_name_english\": [\"unknown\"] * len(missing_categories)})\n",
    "    missing_categories_df.to_sql('olist_productcategorynametranslation', engine, if_exists='append', index=False)\n",
    "\n",
    "data[\"product_category_name_translation\"].fillna(\"unknown_category\", inplace=True)\n",
    "\n",
    "data.to_sql('olist_product', engine, if_exists='append', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sellers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lire le fichier CSV avec pandas\n",
    "data = pd.read_csv(\"data/olist_sellers_dataset.csv\", encoding=\"utf-8\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajouter les codes postaux manquants\n",
    "unique_zip_codes = data['seller_zip_code_prefix'].drop_duplicates().to_frame()\n",
    "unique_zip_codes.columns = ['zip_code_prefix']\n",
    "unique_zip_codes['zip_code_prefix'] = unique_zip_codes['zip_code_prefix'].astype(str)\n",
    "\n",
    "existing_zip_codes = pd.read_sql(\"SELECT zip_code_prefix FROM olist_zipcode\", engine)\n",
    "existing_zip_codes['zip_code_prefix'] = existing_zip_codes['zip_code_prefix'].astype(str)\n",
    "\n",
    "# Fusionner les deux dataframes pour trouver les codes postaux manquants\n",
    "missing_zip_codes = unique_zip_codes.merge(existing_zip_codes, on='zip_code_prefix', how='left', indicator=True)\n",
    "missing_zip_codes = missing_zip_codes[missing_zip_codes['_merge'] == 'left_only'][['zip_code_prefix']]\n",
    "\n",
    "# Ajouter les codes postaux manquants à la table olist_zipcode\n",
    "missing_zip_codes.to_sql('olist_zipcode', engine, if_exists='append', index=False)\n",
    "\n",
    "# Ajouter les états manquants\n",
    "unique_states = data['seller_state'].drop_duplicates()\n",
    "states_db = pd.read_sql(\"SELECT state_code FROM olist_state\", engine)\n",
    "missing_states = unique_states.loc[~unique_states.isin(states_db['state_code'])]\n",
    "missing_states = pd.DataFrame(missing_states, columns=['state_code'])\n",
    "missing_states.to_sql('olist_state', engine, if_exists='append', index=False)\n",
    "\n",
    "# Ajouter les villes manquantes\n",
    "unique_cities = data[['seller_city', 'seller_state']].drop_duplicates()\n",
    "cities_db = pd.read_sql(\"SELECT city_name, state_code FROM olist_city\", engine)\n",
    "missing_cities = unique_cities.merge(cities_db, left_on=['seller_city', 'seller_state'], right_on=['city_name', 'state_code'], how='left', indicator=True)\n",
    "missing_cities = missing_cities[missing_cities['_merge'] == 'left_only'][['seller_city', 'seller_state']]\n",
    "missing_cities.columns = ['city_name', 'state_code'] # Renommer les colonnes pour correspondre à la table city\n",
    "missing_cities.to_sql('olist_city', engine, if_exists='append', index=False)\n",
    "\n",
    "# Maintenant, ajouter les relations manquantes entre les villes et les codes postaux\n",
    "cities_db = pd.read_sql(\"SELECT city_id, city_name, state_code FROM olist_city\", engine)\n",
    "city_zip_codes = data[['seller_city', 'seller_state', 'seller_zip_code_prefix']].drop_duplicates()\n",
    "city_zip_codes_joined = city_zip_codes.merge(cities_db, left_on=['seller_city', 'seller_state'], right_on=['city_name', 'state_code'])\n",
    "city_zip_codes_joined = city_zip_codes_joined[['city_id', 'seller_zip_code_prefix']]\n",
    "city_zip_codes_joined.columns = ['city_id', 'zip_code_prefix']  # Renommer les colonnes pour correspondre à la table city_zip_code\n",
    "\n",
    "existing_city_zip_codes = pd.read_sql(\"SELECT city_id, zip_code_prefix FROM olist_cityzipcode\", engine)\n",
    "\n",
    "# Convertir les types de données pour qu'ils correspondent\n",
    "city_zip_codes_joined['city_id'] = city_zip_codes_joined['city_id'].astype(int)\n",
    "city_zip_codes_joined['zip_code_prefix'] = city_zip_codes_joined['zip_code_prefix'].astype(str)\n",
    "existing_city_zip_codes['city_id'] = existing_city_zip_codes['city_id'].astype(int)\n",
    "existing_city_zip_codes['zip_code_prefix'] = existing_city_zip_codes['zip_code_prefix'].astype(str)\n",
    "\n",
    "city_zip_codes_to_insert = city_zip_codes_joined.merge(existing_city_zip_codes, on=['city_id', 'zip_code_prefix'], how='left', indicator=True)\n",
    "city_zip_codes_to_insert = city_zip_codes_to_insert[city_zip_codes_to_insert['_merge'] == 'left_only'][['city_id', 'zip_code_prefix']]\n",
    "\n",
    "city_zip_codes_to_insert.to_sql('olist_cityzipcode', engine, if_exists='append', index=False)\n",
    "\n",
    "# Insérer les données des vendeurs dans la table Seller\n",
    "sellers_data = data[['seller_id', 'seller_zip_code_prefix']].copy()\n",
    "sellers_data.columns = ['seller_id', 'zip_code_prefix']  # Renommer la colonne pour correspondre au modèle\n",
    "sellers_data.to_sql('olist_seller', engine, if_exists='append', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
